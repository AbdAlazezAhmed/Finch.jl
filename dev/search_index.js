var documenterSearchIndex = {"docs":
[{"location":"fibers/","page":"Array Formats","title":"Array Formats","text":"CurrentModule = Finch","category":"page"},{"location":"fibers/#Level-Formats","page":"Array Formats","title":"Level Formats","text":"","category":"section"},{"location":"fibers/","page":"Array Formats","title":"Array Formats","text":"Finch implements a flexible array datastructure called a fiber. Fibers represent arrays as rooted trees, where the child of each node is selected by an array index. Finch is column major, so in an expression A[i_1, ..., i_N], the rightmost dimension i_N corresponds to the root level of the tree, and the leftmost dimension i_1 corresponds to the leaf level. When the array is dense, the leftmost dimension has stop 1. We can convert the matrix A to a fiber with the @fiber constructor:","category":"page"},{"location":"fibers/","page":"Array Formats","title":"Array Formats","text":"(Image: Example Matrix)","category":"page"},{"location":"fibers/","page":"Array Formats","title":"Array Formats","text":"julia> A = [0.0 0.0 4.4; 1.1 0.0 0.0; 2.2 0.0 5.5; 3.3 0.0 0.0]\n4×3 Matrix{Float64}:\n 0.0  0.0  4.4\n 1.1  0.0  0.0\n 2.2  0.0  5.5\n 3.3  0.0  0.0\njulia> A_fbr = @fiber(d(d(e(0.0))), A)\nDense [:,1:3]\n├─[:,1]: Dense [1:4]\n│ ├─[1]: 0.0\n│ ├─[2]: 1.1\n│ ├─[3]: 2.2\n│ ├─[4]: 3.3\n├─[:,2]: Dense [1:4]\n│ ├─[1]: 0.0\n│ ├─[2]: 0.0\n│ ├─[3]: 0.0\n│ ├─[4]: 0.0\n├─[:,3]: Dense [1:4]\n│ ├─[1]: 4.4\n│ ├─[2]: 0.0\n│ ├─[3]: 5.5\n│ ├─[4]: 0.0","category":"page"},{"location":"fibers/","page":"Array Formats","title":"Array Formats","text":"We refer to a node in the tree as a subfiber. All of the nodes at the same level are stored in the same datastructure, and disambiguated by an integer position.  In the above example, there are three levels: The rootmost level contains only one fiber, the root. The middle level has 3 subfibers, one for each column. The leafmost level has 12 subfibers, one for each element of the array.  For example, the first level is A_fbr.lvl, and we can represent it's third position as SubFiber(A_fbr.lvl.lvl, 3). The second level is A_fbr.lvl.lvl, and we can access it's 9th position as SubFiber(A_fbr.lvl.lvl.lvl, 9). For instructional purposes, you can use parentheses to call a fiber on an index to select among children of a fiber.","category":"page"},{"location":"fibers/","page":"Array Formats","title":"Array Formats","text":"julia> Finch.SubFiber(A_fbr.lvl.lvl, 3)\nDense [1:4]\n├─[1]: 4.4\n├─[2]: 0.0\n├─[3]: 5.5\n├─[4]: 0.0\n\njulia> A_fbr[:, 3]\nDense [1:4]\n├─[1]: 4.4\n├─[2]: 0.0\n├─[3]: 5.5\n├─[4]: 0.0\n\njulia> A_fbr(3)\nDense [1:4]\n├─[1]: 4.4\n├─[2]: 0.0\n├─[3]: 5.5\n├─[4]: 0.0\n\njulia> Finch.SubFiber(A_fbr.lvl.lvl.lvl, 9)\n4.4\n\njulia> A_fbr[1, 3]\n4.4\n\njulia> A_fbr(3)(1)\n4.4\n","category":"page"},{"location":"fibers/","page":"Array Formats","title":"Array Formats","text":"When we print the tree in text, positions are numbered from top to bottom. However, if we visualize our tree with the root at the top, positions range from left to right:","category":"page"},{"location":"fibers/","page":"Array Formats","title":"Array Formats","text":"(Image: Dense Format Index Tree)","category":"page"},{"location":"fibers/","page":"Array Formats","title":"Array Formats","text":"Because our array is sparse, (mostly zero, or another fill value), it would be more efficient to store only the nonzero values. In Finch, each level is represented with a different format. A sparse level only stores non-fill values. This time, we'll use a fiber constructor with sl (for \"SparseList of nonzeros\") instead of d (for \"Dense\"):","category":"page"},{"location":"fibers/","page":"Array Formats","title":"Array Formats","text":"julia> A_fbr = @fiber(d(sl(e(0.0))), A)\nDense [:,1:3]\n├─[:,1]: SparseList (0.0) [1:4]\n│ ├─[2]: 1.1\n│ ├─[3]: 2.2\n│ ├─[4]: 3.3\n├─[:,2]: SparseList (0.0) [1:4]\n├─[:,3]: SparseList (0.0) [1:4]\n│ ├─[1]: 4.4\n│ ├─[3]: 5.5","category":"page"},{"location":"fibers/","page":"Array Formats","title":"Array Formats","text":"(Image: CSC Format Index Tree)","category":"page"},{"location":"fibers/","page":"Array Formats","title":"Array Formats","text":"Our d(sl(e(0.0))) format is also known as \"CSC\" and is equivalent to SparseMatrixCSC. The fiber! function will perform a zero-cost copy between Finch fibers and sparse matrices, when available.  CSC is an excellent general-purpose representation when we expect most of the columns to have a few nonzeros. However, when most of the columns are entirely fill (a situation known as hypersparsity), it is better to compress the root level as well:","category":"page"},{"location":"fibers/","page":"Array Formats","title":"Array Formats","text":"julia> A_fbr = @fiber(sl(sl(e(0.0))), A)\nSparseList (0.0) [:,1:3]\n├─[:,1]: SparseList (0.0) [1:4]\n│ ├─[2]: 1.1\n│ ├─[3]: 2.2\n│ ├─[4]: 3.3\n├─[:,3]: SparseList (0.0) [1:4]\n│ ├─[1]: 4.4\n│ ├─[3]: 5.5","category":"page"},{"location":"fibers/","page":"Array Formats","title":"Array Formats","text":"(Image: DCSC Format Index Tree)","category":"page"},{"location":"fibers/","page":"Array Formats","title":"Array Formats","text":"Here we see that the entirely zero column has also been compressed. The sl(sl(e(0.0))) format is also known as \"DCSC\".","category":"page"},{"location":"fibers/","page":"Array Formats","title":"Array Formats","text":"The \"COO\" (or \"Coordinate\") format is often used in practice for ease of interchange between libraries. In an N-dimensional array A, COO stores N lists of indices I_1, ..., I_N where A[I_1[p], ..., I_N[p]] is the p^th stored value in column-major numbering. In Finch, COO is represented as a multi-index level, which can handle more than one index at once. We use curly brackets to declare the number of indices handled by the level:","category":"page"},{"location":"fibers/","page":"Array Formats","title":"Array Formats","text":"julia> A_fbr = @fiber(sc{2}(e(0.0)), A)\nSparseCOO (0.0) [1:4,1:3]\n├─├─[2, 1]: 1.1\n├─├─[3, 1]: 2.2\n├─├─[4, 1]: 3.3\n├─├─[1, 3]: 4.4\n├─├─[3, 3]: 5.5","category":"page"},{"location":"fibers/","page":"Array Formats","title":"Array Formats","text":"(Image: COO Format Index Tree)","category":"page"},{"location":"fibers/","page":"Array Formats","title":"Array Formats","text":"The COO format is compact and straightforward, but doesn't support random access. For random access, one should use the SparseHash format. A full listing of supported formats is described below:","category":"page"},{"location":"fibers/#Public-Functions","page":"Array Formats","title":"Public Functions","text":"","category":"section"},{"location":"fibers/#Fiber-Constructors","page":"Array Formats","title":"Fiber Constructors","text":"","category":"section"},{"location":"fibers/","page":"Array Formats","title":"Array Formats","text":"@fiber\nfiber\nfiber!\nfiber_abbrev","category":"page"},{"location":"fibers/#Finch.@fiber","page":"Array Formats","title":"Finch.@fiber","text":"@fiber ctr [arg]\n\nConstruct a fiber using abbreviated level constructor names. To override abbreviations, expressions may be interpolated with $. For example, Fiber(DenseLevel(SparseListLevel(Element(0.0)))) can also be constructed as @fiber(sl(d(e(0.0)))). Consult the documentation for the helper function fiber_abbrev for a full listing of level format abbreviations.\n\nOptionally, an argument may be specified to copy into the fiber. This expression allocates. Use fiber(arg) for a zero-cost copy, if available.\n\n\n\n\n\n","category":"macro"},{"location":"fibers/#Finch.fiber","page":"Array Formats","title":"Finch.fiber","text":"fiber(arr, default = zero(eltype(arr)))\n\nCopies an array-like object arr into a corresponding, similar Fiber datastructure. default is the default value to use for initialization and sparse compression.\n\nSee also: fiber!\n\nExamples\n\njulia> println(summary(fiber(sparse([1 0; 0 1]))))\n2×2 @fiber(d(sl(e(0))))\n\njulia> println(summary(fiber(ones(3, 2, 4))))\n3×2×4 @fiber(d(d(d(e(0.0)))))\n\n\n\n\n\n","category":"function"},{"location":"fibers/#Finch.fiber!","page":"Array Formats","title":"Finch.fiber!","text":"fiber!(arr, default = zero(eltype(arr)))\n\nLike fiber, copies an array-like object arr into a corresponding, similar Fiber datastructure. However, fiber! reuses memory whenever possible, meaning arr may be rendered unusable.\n\n\n\n\n\n","category":"function"},{"location":"fibers/#Finch.fiber_abbrev","page":"Array Formats","title":"Finch.fiber_abbrev","text":"fiber_abbrev(l) = SparseListLevel.\n\n\n\n\n\nfiber_abbrev(sh) = SparseHashLevel.\n\n\n\n\n\nfiber_abbrev(sc) = SparseCOOLevel.\n\n\n\n\n\nfiber_abbrev(sbm) = SparseByteMapLevel.\n\n\n\n\n\nfiber_abbrev(svb) = SparseVBLLevel.\n\n\n\n\n\nfiber_abbrev(d) = DenseLevel.\n\n\n\n\n\nfiber_abbrev(rl) = RepeatRLELevel.\n\n\n\n\n\nfiber_abbrev(e) = ElementLevel.\n\n\n\n\n\nfiber_abbrev(p) = PatternLevel.\n\n\n\n\n\nfiber_abbrev(st) = SparseTriangleLevel.\n\n\n\n\n\n","category":"function"},{"location":"fibers/#Level-Constructors","page":"Array Formats","title":"Level Constructors","text":"","category":"section"},{"location":"fibers/","page":"Array Formats","title":"Array Formats","text":"DenseLevel\nElementLevel\nSparseListLevel\nSparseCOOLevel\nSparseHashLevel","category":"page"},{"location":"fibers/#Finch.DenseLevel","page":"Array Formats","title":"Finch.DenseLevel","text":"DenseLevel{[Ti=Int]}(lvl, [dim])\n\nA subfiber of a dense level is an array which stores every slice A[:, ..., :, i] as a distinct subfiber in lvl. Optionally, dim is the size of the last dimension. Ti is the type of the indices used to index the level.\n\nIn the @fiber constructor, d is an alias for DenseLevel.\n\njulia> ndims(@fiber(d(e(0.0))))\n1\n\njulia> ndims(@fiber(d(d(e(0.0)))))\n2\n\njulia> @fiber(d(d(e(0.0))), [1 2; 3 4])\nDense [:,1:2]\n├─[:,1]: Dense [1:2]\n│ ├─[1]: 1.0\n│ ├─[2]: 3.0\n├─[:,2]: Dense [1:2]\n│ ├─[1]: 2.0\n│ ├─[2]: 4.0\n\n\n\n\n\n","category":"type"},{"location":"fibers/#Finch.ElementLevel","page":"Array Formats","title":"Finch.ElementLevel","text":"ElementLevel{D, [Tv]}()\n\nA subfiber of an element level is a scalar of type Tv, initialized to D. D may optionally be given as the first argument.\n\nIn the @fiber constructor, e is an alias for ElementLevel.\n\njulia> @fiber(d(e(0.0)), [1, 2, 3])\nDense [1:3]\n├─[1]: 1.0\n├─[2]: 2.0\n├─[3]: 3.0\n\n\n\n\n\n","category":"type"},{"location":"fibers/#Finch.SparseListLevel","page":"Array Formats","title":"Finch.SparseListLevel","text":"SparseListLevel{[Ti=Int], [Tp=Int]}(lvl, [dim])\n\nA subfiber of a sparse level does not need to represent slices A[:, ..., :, i] which are entirely default. Instead, only potentially non-default slices are stored as subfibers in lvl.  A sorted list is used to record which slices are stored. Optionally, dim is the size of the last dimension.\n\nTi is the type of the last fiber index, and Tp is the type used for positions in the level.\n\nIn the @fiber constructor, sl is an alias for SparseListLevel.\n\njulia> @fiber(d(sl(e(0.0))), [10 0 20; 30 0 0; 0 0 40])\nDense [:,1:3]\n├─[:,1]: SparseList (0.0) [1:3]\n│ ├─[1]: 10.0\n│ ├─[2]: 30.0\n├─[:,2]: SparseList (0.0) [1:3]\n├─[:,3]: SparseList (0.0) [1:3]\n│ ├─[1]: 20.0\n│ ├─[3]: 40.0\n\njulia> @fiber(sl(sl(e(0.0))), [10 0 20; 30 0 0; 0 0 40])\nSparseList (0.0) [:,1:3]\n├─[:,1]: SparseList (0.0) [1:3]\n│ ├─[1]: 10.0\n│ ├─[2]: 30.0\n├─[:,3]: SparseList (0.0) [1:3]\n│ ├─[1]: 20.0\n│ ├─[3]: 40.0\n\n\n\n\n\n\n","category":"type"},{"location":"fibers/#Finch.SparseCOOLevel","page":"Array Formats","title":"Finch.SparseCOOLevel","text":"SparseCOOLevel{[N], [Ti=Tuple{Int...}], [Tp=Int]}(lvl, [dims])\n\nA subfiber of a sparse level does not need to represent slices which are entirely default. Instead, only potentially non-default slices are stored as subfibers in lvl. The sparse coo level corresponds to N indices in the subfiber, so fibers in the sublevel are the slices A[:, ..., :, i_1, ..., i_n].  A set of N lists (one for each index) are used to record which slices are stored. The coordinates (sets of N indices) are sorted in column major order.  Optionally, dims are the sizes of the last dimensions.\n\nTi is the type of the last N fiber indices, and Tp is the type used for positions in the level.\n\nIn the @fiber constructor, sh is an alias for SparseCOOLevel.\n\njulia> @fiber(d(sc{1}(e(0.0))), [10 0 20; 30 0 0; 0 0 40])\nDense [:,1:3]\n├─[:,1]: SparseCOO (0.0) [1:3]\n│ ├─[1]: 10.0\n│ ├─[2]: 30.0\n├─[:,2]: SparseCOO (0.0) [1:3]\n├─[:,3]: SparseCOO (0.0) [1:3]\n│ ├─[1]: 20.0\n│ ├─[3]: 40.0\n\njulia> @fiber(sc{2}(e(0.0)), [10 0 20; 30 0 0; 0 0 40])\nSparseCOO (0.0) [1:3,1:3]\n├─├─[1, 1]: 10.0\n├─├─[2, 1]: 30.0\n├─├─[1, 3]: 20.0\n├─├─[3, 3]: 40.0\n\n\n\n\n\n","category":"type"},{"location":"fibers/#Finch.SparseHashLevel","page":"Array Formats","title":"Finch.SparseHashLevel","text":"SparseHashLevel{[N], [Ti=Tuple{Int...}], [Tp=Int]}(lvl, [dims])\n\nA subfiber of a sparse level does not need to represent slices which are entirely default. Instead, only potentially non-default slices are stored as subfibers in lvl. The sparse hash level corresponds to N indices in the subfiber, so fibers in the sublevel are the slices A[:, ..., :, i_1, ..., i_n].  A hash table is used to record which slices are stored. Optionally, dims are the sizes of the last dimensions.\n\nTi is the type of the last N fiber indices, and Tp is the type used for positions in the level.\n\nIn the @fiber constructor, sh is an alias for SparseHashLevel.\n\njulia> @fiber(d(sh{1}(e(0.0))), [10 0 20; 30 0 0; 0 0 40])\nDense [:,1:3]\n├─[:,1]: SparseHash (0.0) [1:3]\n│ ├─[1]: 10.0\n│ ├─[2]: 30.0\n├─[:,2]: SparseHash (0.0) [1:3]\n├─[:,3]: SparseHash (0.0) [1:3]\n│ ├─[1]: 20.0\n│ ├─[3]: 40.0\n\njulia> @fiber(sh{2}(e(0.0)), [10 0 20; 30 0 0; 0 0 40])\nSparseHash (0.0) [1:3,1:3]\n├─├─[1, 1]: 10.0\n├─├─[2, 1]: 30.0\n├─├─[1, 3]: 20.0\n├─├─[3, 3]: 40.0\n\n\n\n\n\n","category":"type"},{"location":"development/","page":"Development Guide","title":"Development Guide","text":"CurrentModule = Finch","category":"page"},{"location":"development/#Development-Guide","page":"Development Guide","title":"Development Guide","text":"","category":"section"},{"location":"development/","page":"Development Guide","title":"Development Guide","text":"We welcome contributions to Finch! Before you start, please double-check in a Github issue that there is interest from a contributor in moderating your potential pull request.","category":"page"},{"location":"development/#Testing","page":"Development Guide","title":"Testing","text":"","category":"section"},{"location":"development/","page":"Development Guide","title":"Development Guide","text":"All pull requests should pass continuous integration testing before merging. For more information about running tests (including filtering test suites or updating the reference output), run the test script directly:","category":"page"},{"location":"development/","page":"Development Guide","title":"Development Guide","text":"julia tests/runtests.jl --help","category":"page"},{"location":"development/#Finch-Compilation-Pipeline","page":"Development Guide","title":"Finch Compilation Pipeline","text":"","category":"section"},{"location":"development/#Program-Instances","page":"Development Guide","title":"Program Instances","text":"","category":"section"},{"location":"development/","page":"Development Guide","title":"Development Guide","text":"Finch relies heavily on Julia's metaprogramming capabilities ( macros and generated functions in particular) to produce code. To review briefly, a macro allows us to inspect the syntax of it's arguments and generate replacement syntax. A generated function allows us to inspect the type of the function arguments and produce code for a function body.","category":"page"},{"location":"development/","page":"Development Guide","title":"Development Guide","text":"In normal Finch usage, we might call Finch as follows:","category":"page"},{"location":"development/","page":"Development Guide","title":"Development Guide","text":"julia> C = @fiber(sl(e(0)));\n\njulia> A = @fiber(sl(e(0)), [0, 2, 0, 0, 3]);\n\njulia> B = @fiber(d(e(0)), [11, 12, 13, 14, 15]);\n\njulia> @finch (C .= 0; @loop i C[i] = A[i] * B[i]);\n\njulia> C\nSparseList (0) [1:5]\n├─[2]: 24\n├─[5]: 45","category":"page"},{"location":"development/","page":"Development Guide","title":"Development Guide","text":"The @macroexpand macro allows us to see the result of applying a macro. Let's examine what happens when we use the @finch macro (we've stripped line numbers from the result to clean it up):","category":"page"},{"location":"development/","page":"Development Guide","title":"Development Guide","text":"julia> (@macroexpand @finch (C .= 0; @loop i C[i] = A[i] * B[i])) |> Finch.striplines |> Finch.regensym\nquote\n    _res_1 = (Finch.execute)((Finch.FinchNotation.sequence_instance)((Finch.FinchNotation.declare_instance)((Finch.FinchNotation.variable_instance)(:C, (Finch.FinchNotation.finch_leaf_instance)(C)), literal_instance(0)), begin\n                    let i = index_instance(:i)\n                        (Finch.FinchNotation.loop_instance)(i, (Finch.FinchNotation.assign_instance)((Finch.FinchNotation.access_instance)((Finch.FinchNotation.variable_instance)(:C, (Finch.FinchNotation.finch_leaf_instance)(C)), (Finch.FinchNotation.updater_instance)((Finch.FinchNotation.create_instance)()), (Finch.FinchNotation.variable_instance)(:i, (Finch.FinchNotation.finch_leaf_instance)(i))), (Finch.FinchNotation.literal_instance)((Finch.FinchNotation.initwrite)((Finch.default)(C))), (Finch.FinchNotation.call_instance)((Finch.FinchNotation.variable_instance)(:*, (Finch.FinchNotation.finch_leaf_instance)(*)), (Finch.FinchNotation.access_instance)((Finch.FinchNotation.variable_instance)(:A, (Finch.FinchNotation.finch_leaf_instance)(A)), (Finch.FinchNotation.reader_instance)(), (Finch.FinchNotation.variable_instance)(:i, (Finch.FinchNotation.finch_leaf_instance)(i))), (Finch.FinchNotation.access_instance)((Finch.FinchNotation.variable_instance)(:B, (Finch.FinchNotation.finch_leaf_instance)(B)), (Finch.FinchNotation.reader_instance)(), (Finch.FinchNotation.variable_instance)(:i, (Finch.FinchNotation.finch_leaf_instance)(i))))))\n                    end\n                end))\n    begin\n        C = Finch.get(_res_1, :C, C)\n    end\n    begin\n        _res_1\n    end\nend\n","category":"page"},{"location":"development/","page":"Development Guide","title":"Development Guide","text":"In the above output, @finch creates an AST of program instances, then calls Finch.execute on it. A program instance is a struct that contains the program to be executed along with its arguments. Although we can use the above constructors (e.g. loop_instance) to make our own program instance, it is most convenient to use the unexported macro Finch.finch_program_instance:","category":"page"},{"location":"development/","page":"Development Guide","title":"Development Guide","text":"julia> using Finch: @finch_program_instance\n\njulia> prgm = Finch.@finch_program_instance (C .= 0; @loop i C[i] = A[i] * B[i])\nsequence_instance(declare_instance(variable_instance(:C, C), literal_instance(0)), loop_instance(index_instance(:i), assign_instance(access_instance(variable_instance(:C, C), updater_instance(create_instance()), index_instance(:i)), literal_instance(Finch.FinchNotation.InitWriter{0}()), call_instance(variable_instance(:*, *), access_instance(variable_instance(:A, A), reader_instance(), index_instance(:i)), access_instance(variable_instance(:B, B), reader_instance(), index_instance(:i))))))","category":"page"},{"location":"development/","page":"Development Guide","title":"Development Guide","text":"As we can see, our program instance contains not only the AST to be executed, but also the data to execute the program with. The type of the program instance contains only the program portion; there may be many program instances with different inputs, but the same program type. We can run our program using Finch.execute, which returns a NamedTuple of outputs.","category":"page"},{"location":"development/","page":"Development Guide","title":"Development Guide","text":"julia> typeof(prgm)\nFinch.FinchNotation.SequenceInstance{Tuple{Finch.FinchNotation.DeclareInstance{Finch.FinchNotation.VariableInstance{:C, Fiber{SparseListLevel{Int64, Int64, ElementLevel{0, Int64}}}}, Finch.FinchNotation.LiteralInstance{0}}, Finch.FinchNotation.LoopInstance{Finch.FinchNotation.IndexInstance{:i}, Finch.FinchNotation.AssignInstance{Finch.FinchNotation.AccessInstance{Finch.FinchNotation.VariableInstance{:C, Fiber{SparseListLevel{Int64, Int64, ElementLevel{0, Int64}}}}, Finch.FinchNotation.UpdaterInstance{Finch.FinchNotation.CreateInstance}, Tuple{Finch.FinchNotation.IndexInstance{:i}}}, Finch.FinchNotation.LiteralInstance{Finch.FinchNotation.InitWriter{0}()}, Finch.FinchNotation.CallInstance{Finch.FinchNotation.VariableInstance{:*, Finch.FinchNotation.LiteralInstance{*}}, Tuple{Finch.FinchNotation.AccessInstance{Finch.FinchNotation.VariableInstance{:A, Fiber{SparseListLevel{Int64, Int64, ElementLevel{0, Int64}}}}, Finch.FinchNotation.ReaderInstance, Tuple{Finch.FinchNotation.IndexInstance{:i}}}, Finch.FinchNotation.AccessInstance{Finch.FinchNotation.VariableInstance{:B, Fiber{DenseLevel{Int64, ElementLevel{0, Int64}}}}, Finch.FinchNotation.ReaderInstance, Tuple{Finch.FinchNotation.IndexInstance{:i}}}}}}}}}\n\njulia> C = Finch.execute(prgm).C\nSparseList (0) [1:5]\n├─[2]: 24\n├─[5]: 45","category":"page"},{"location":"development/","page":"Development Guide","title":"Development Guide","text":"This functionality is sufficient for building finch kernels programatically. For example, if we wish to define a function pointwise_sum() that takes the pointwise sum of a variable number of vector inputs, we might implement it as follows:","category":"page"},{"location":"development/","page":"Development Guide","title":"Development Guide","text":"julia> function pointwise_sum(As...)\n           B = @fiber(d(e(0)))\n           isempty(As) && return B\n           i = Finch.FinchNotation.index_instance(:i)\n           A_vars = [Finch.FinchNotation.variable_instance(Symbol(:A, n), As[n]) for n in 1:length(As)]\n           #create a list of variable instances with different names to hold the input tensors\n           ex = @finch_program_instance 0\n           for A_var in A_vars\n               ex = @finch_program_instance $A_var[i] + $ex\n           end\n           prgm = @finch_program_instance (B .= 0; @loop i B[i] = $ex)\n           return Finch.execute(prgm).B\n       end\npointwise_sum (generic function with 1 method)\n\njulia> pointwise_sum([1, 2], [3, 4])\nDense [1:2]\n├─[1]: 4\n├─[2]: 6\n","category":"page"},{"location":"development/#Virtualization","page":"Development Guide","title":"Virtualization","text":"","category":"section"},{"location":"development/","page":"Development Guide","title":"Development Guide","text":"TODO more on the way...","category":"page"},{"location":"development/#Tensor-Life-Cycle","page":"Development Guide","title":"Tensor Life Cycle","text":"","category":"section"},{"location":"development/","page":"Development Guide","title":"Development Guide","text":"Every virtual tensor must be in one of two modes: read-only mode or update-only mode. The following functions may be called on virtual tensors throughout their life cycle.","category":"page"},{"location":"development/","page":"Development Guide","title":"Development Guide","text":"declare!\nget_reader\nget_updater\nfreeze!\ntrim!","category":"page"},{"location":"development/#Finch.declare!","page":"Development Guide","title":"Finch.declare!","text":"declare!(tns, ctx, init)\n\nDeclare the read-only virtual tensor tns in the context ctx with a starting value of init and return it. Afterwards the tensor is update-only.\n\n\n\n\n\n","category":"function"},{"location":"development/#Finch.get_reader","page":"Development Guide","title":"Finch.get_reader","text":"get_reader(tns, ctx, protos...)\n\nReturn an object (usually a looplet nest) capable of reading the read-only virtual tensor tns.  As soon as a read-only tensor enters scope, each subsequent read access will be initialized with a separate call to get_reader. protos is the list of protocols in each case.\n\n\n\n\n\n","category":"function"},{"location":"development/#Finch.get_updater","page":"Development Guide","title":"Finch.get_updater","text":"get_updater(tns, ctx, protos...)\n\nReturn an object (usually a looplet nest) capable of updating the update-only virtual tensor tns.  As soon as an update only tensor enters scope, each subsequent update access will be initialized with a separate call to get_updater.  protos is the list of protocols in each case.\n\n\n\n\n\n","category":"function"},{"location":"development/#Finch.freeze!","page":"Development Guide","title":"Finch.freeze!","text":"freeze!(tns, ctx)\n\nFreeze the update-only virtual tensor tns in the context ctx and return it. Afterwards, the tensor is read-only.\n\n\n\n\n\n","category":"function"},{"location":"development/#Finch.trim!","page":"Development Guide","title":"Finch.trim!","text":"trim!(tns, ctx)\n\nBefore returning a tensor from the finch program, trim any excess overallocated memory.\n\n\n\n\n\n","category":"function"},{"location":"development/#Fiber-internals","page":"Development Guide","title":"Fiber internals","text":"","category":"section"},{"location":"development/","page":"Development Guide","title":"Development Guide","text":"Fiber levels are implemented using the following methods:","category":"page"},{"location":"development/","page":"Development Guide","title":"Development Guide","text":"default\ndeclare_level!\nassemble_level!\nreassemble_level!\nfreeze_level!\nlevel_ndims\nlevel_size\nlevel_axes\nlevel_eltype\nlevel_default","category":"page"},{"location":"development/#Finch.default","page":"Development Guide","title":"Finch.default","text":"default(fbr)\n\nThe default for a fiber is the value that each element of the fiber will have after initialization. This value is most often zero, and defaults to nothing.\n\nSee also: declare!\n\n\n\n\n\n","category":"function"},{"location":"development/#Finch.declare_level!","page":"Development Guide","title":"Finch.declare_level!","text":"declare_level!(lvl, ctx, pos, init)\n\nInitialize and thaw all fibers within lvl, assuming positions 1:pos were previously assembled and frozen. The resulting level has no assembled positions.\n\n\n\n\n\n","category":"function"},{"location":"development/#Finch.assemble_level!","page":"Development Guide","title":"Finch.assemble_level!","text":"assemble_level!(lvl, ctx, pos, new_pos)\n\nAssemble and positions pos+1:new_pos in lvl, assuming positions 1:pos were previously assembled.\n\n\n\n\n\n","category":"function"},{"location":"development/#Finch.reassemble_level!","page":"Development Guide","title":"Finch.reassemble_level!","text":"reassemble_level!(lvl, ctx, pos_start, pos_end)\n\nSet the previously assempled positions from pos_start to pos_end to level_default(lvl).\n\n\n\n\n\n","category":"function"},{"location":"development/#Finch.freeze_level!","page":"Development Guide","title":"Finch.freeze_level!","text":"freeze_level!(lvl, ctx, pos)\n\nFreeze all fibers in lvl. Positions 1:pos need freezing.\n\n\n\n\n\n","category":"function"},{"location":"development/#Finch.level_ndims","page":"Development Guide","title":"Finch.level_ndims","text":"level_ndims(::Type{Lvl})\n\nThe result of level_ndims(Lvl) defines ndims for all subfibers in a level of type Lvl.\n\n\n\n\n\n","category":"function"},{"location":"development/#Finch.level_size","page":"Development Guide","title":"Finch.level_size","text":"level_size(lvl)\n\nThe result of level_size(lvl) defines the size of all subfibers in the level lvl.\n\n\n\n\n\n","category":"function"},{"location":"development/#Finch.level_axes","page":"Development Guide","title":"Finch.level_axes","text":"level_axes(lvl)\n\nThe result of level_axes(lvl) defines the axes of all subfibers in the level lvl.\n\n\n\n\n\n","category":"function"},{"location":"development/#Finch.level_eltype","page":"Development Guide","title":"Finch.level_eltype","text":"level_eltype(::Type{Lvl})\n\nThe result of level_eltype(Lvl) defines eltype for all subfibers in a level of type Lvl.\n\n\n\n\n\n","category":"function"},{"location":"development/#Finch.level_default","page":"Development Guide","title":"Finch.level_default","text":"level_default(::Type{Lvl})\n\nThe result of level_default(Lvl) defines default for all subfibers in a level of type Lvl.\n\n\n\n\n\n","category":"function"},{"location":"interop/#Using-Finch-with-Other-Languages","page":"C, C++, ...","title":"Using Finch with Other Languages","text":"","category":"section"},{"location":"interop/","page":"C, C++, ...","title":"C, C++, ...","text":"You can use Finch in other languages through our C interface! We also include convenience types for converting between 0-indexed and 1-indexed arrays.","category":"page"},{"location":"interop/#finch.h","page":"C, C++, ...","title":"finch.h","text":"","category":"section"},{"location":"interop/","page":"C, C++, ...","title":"C, C++, ...","text":"Refer to finch.h for detailed documentation. The public functions include a few shortcuts for constructing finch datatypes, as well as convenience functions for calling Julia from C. Refer also to the Julia documentation for more general advice. Refer to the tests for a working example of embedding in C. Note that calling finch_init will call jl_init, as well as initializing a few function pointers for the interface. Julia cannot see C references to Julia objects, so finch.h includes a few functions to introduce references on the Julia side that mirror C objects.","category":"page"},{"location":"interop/#Index-Compatibility","page":"C, C++, ...","title":"0-Index Compatibility","text":"","category":"section"},{"location":"interop/","page":"C, C++, ...","title":"C, C++, ...","text":"Julia, Matlab, etc. index arrays starting at 1. C, python, etc. index starting at 0. In a dense array, we can simply subtract one from the index, and in fact, this is what Julia will does under the hood when you pass a vector between C to Julia. ","category":"page"},{"location":"interop/","page":"C, C++, ...","title":"C, C++, ...","text":"However, for sparse array formats, it's not just a matter of subtracting one from the index, as the internal lists of indices, positions, etc all start from zero as well. To remedy the situation, Finch defines a handy zero-indexed integer type called CIndex. The internal representation of CIndex is one less than the value it represents, and we can use CIndex as the index or position type of a Finch array to represent arrays in other languages.","category":"page"},{"location":"interop/","page":"C, C++, ...","title":"C, C++, ...","text":"For example, if idx_c, ptr_c, and val_c are the internal arrays of a CSC matrix in a zero-indexed language, we can represent that matrix as a one-indexed Finch array without copying by calling","category":"page"},{"location":"interop/","page":"C, C++, ...","title":"C, C++, ...","text":"DocTestSetup = quote\n    using Finch\n    using Finch: Cindex\nend","category":"page"},{"location":"interop/","page":"C, C++, ...","title":"C, C++, ...","text":"julia> m = 4; n = 3; ptr_c = [0, 3, 3, 5]; idx_c = [1, 2, 3, 0, 2]; val_c = [1.1, 2.2, 3.3, 4.4, 5.5];\n\njulia> ptr_jl = unsafe_wrap(Array, reinterpret(Ptr{Cindex{Int}}, pointer(ptr_c)), length(ptr_c); own = false)\n4-element Vector{Cindex{Int64}}:\n Cindex{Int64}(0)\n Cindex{Int64}(3)\n Cindex{Int64}(3)\n Cindex{Int64}(5)\njulia> idx_jl = unsafe_wrap(Array, reinterpret(Ptr{Cindex{Int}}, pointer(idx_c)), length(idx_c); own = false)\n5-element Vector{Cindex{Int64}}:\n Cindex{Int64}(1)\n Cindex{Int64}(2)\n Cindex{Int64}(3)\n Cindex{Int64}(0)\n Cindex{Int64}(2)\njulia> A = Fiber(Dense(SparseList{Cindex{Int}, Cindex{Int}}(Element{0.0, Float64}(val_c), m, ptr_jl, idx_jl), n))\nDense [:,1:3]\n├─[:,1]: SparseList (0.0) [1:Cindex{Int64}(3)]\n│ ├─[Cindex{Int64}(1)]: 1.1\n│ ├─[Cindex{Int64}(2)]: 2.2\n│ ├─[Cindex{Int64}(3)]: 3.3\n├─[:,2]: SparseList (0.0) [1:Cindex{Int64}(3)]\n├─[:,3]: SparseList (0.0) [1:Cindex{Int64}(3)]\n│ ├─[Cindex{Int64}(0)]: 4.4\n│ ├─[Cindex{Int64}(2)]: 5.5","category":"page"},{"location":"interop/","page":"C, C++, ...","title":"C, C++, ...","text":"We can also convert between representations by by copying to or from Cindex fibers.","category":"page"},{"location":"","page":"Home","title":"Home","text":"CurrentModule = Finch","category":"page"},{"location":"#Finch","page":"Home","title":"Finch","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Finch is an adaptable compiler for loop nests over sparse or otherwise structured arrays. Finch supports general sparsity as well as many specialized sparsity patterns, like clustered nonzeros, diagonals, or triangles.  In addition to zero, Finch supports optimizations over arbitrary fill values and operators, even run-length-compression.","category":"page"},{"location":"","page":"Home","title":"Home","text":"At it's heart, Finch is powered by a domain specific language for coiteration, breaking structured iterators into units we call Looplets. The Looplets are lowered progressively, leaving several opportunities to rewrite and simplify intermediate expressions.","category":"page"},{"location":"#Installation:","page":"Home","title":"Installation:","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"julia> using Pkg; Pkg.add(\"Finch\")","category":"page"},{"location":"#Usage:","page":"Home","title":"Usage:","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"We're working on adding more documentation, for now take a look at the examples for linear algebra or graphs.","category":"page"},{"location":"algebra/","page":"Custom Functions","title":"Custom Functions","text":"CurrentModule = Finch","category":"page"},{"location":"algebra/#Custom-Functions","page":"Custom Functions","title":"Custom Functions","text":"","category":"section"},{"location":"algebra/#User-Functions","page":"Custom Functions","title":"User Functions","text":"","category":"section"},{"location":"algebra/","page":"Custom Functions","title":"Custom Functions","text":"Finch supports arbitrary Julia Base functions over isbits types.  You can also use your own functions and use them in Finch! Just remember to define any special algebraic properties of your functions so that Finch can optimize them better. You must declare the properties of your functions before you call any Finch functions on them.","category":"page"},{"location":"algebra/","page":"Custom Functions","title":"Custom Functions","text":"Finch only supports incrementing assignments to arrays such as += or *=. If you would like to increment A[i...] by the value of ex with a custom reduction operator op, you may use the following syntax: A[i...] <<op>>= ex.","category":"page"},{"location":"algebra/","page":"Custom Functions","title":"Custom Functions","text":"Consider the greatest common divisor function gcd. This function is associative and commutative, and the greatest common divisor of 1 and anything else is 1, so 1 is an annihilator.  We declare these properties by overloading trait functions on Finch's default algebra as follows:","category":"page"},{"location":"algebra/","page":"Custom Functions","title":"Custom Functions","text":"Finch.isassociative(::Finch.DefaultAlgebra, ::typeof(gcd)) = true\nFinch.iscommutative(::Finch.DefaultAlgebra, ::typeof(gcd)) = true\nFinch.isannihilator(::Finch.DefaultAlgebra, ::typeof(gcd), x) = x == 1","category":"page"},{"location":"algebra/","page":"Custom Functions","title":"Custom Functions","text":"Then, the following code will only call gcd when neither u[i] nor v[i] are 1 (just once!).","category":"page"},{"location":"algebra/","page":"Custom Functions","title":"Custom Functions","text":"u = @fiber(sl(e(1)), [3, 1, 6, 1, 9, 1, 4, 1, 8, 1])\nv = @fiber(sl(e(1)), [1, 2, 3, 1, 1, 1, 1, 4, 1, 1])\nw = @fiber sl(e(1))\n\n@finch MyAlgebra() (w .= 1; @loop i w[i] = gcd(u[i], v[i]))","category":"page"},{"location":"algebra/#A-Few-Convenient-Functions","page":"Custom Functions","title":"A Few Convenient Functions","text":"","category":"section"},{"location":"algebra/","page":"Custom Functions","title":"Custom Functions","text":"For your convenience, Finch defines a few useful functions that help express common array operations inside Finch:","category":"page"},{"location":"algebra/","page":"Custom Functions","title":"Custom Functions","text":"choose\nminby\nmaxby","category":"page"},{"location":"algebra/#Finch.choose","page":"Custom Functions","title":"Finch.choose","text":"choose(z)(a, b)\n\nchoose(z) is a function which returns whichever of a or b is not isequal to z. If neither are z, then return a. Useful for getting the first nonfill value in a sparse array.\n\njulia> a = @fiber(sl(e(0.0)), [0, 1.1, 0, 4.4, 0])\nSparseList (0.0) [1:5]\n├─[2]: 1.1\n├─[4]: 4.4\n\njulia> x = Scalar(0.0); @finch @loop i x[] <<choose(0.0)>>= a[i];\n\njulia> x[]\n1.1\n\n\n\n\n\n","category":"function"},{"location":"algebra/#Finch.minby","page":"Custom Functions","title":"Finch.minby","text":"minby(a, b)\n\nReturn the min of a or b, comparing them by a[1] and b[1], and breaking ties to the left. Useful for implementing argmin operations:\n\njulia> a = [7.7, 3.3, 9.9, 3.3, 9.9]; x = Scalar(Inf => 0);\n\njulia> @finch @loop i x[] <<minby>>= a[i] => i;\n\njulia> x[]\n3.3 => 2\n\n\n\n\n\n","category":"function"},{"location":"algebra/#Finch.maxby","page":"Custom Functions","title":"Finch.maxby","text":"maxby(a, b)\n\nReturn the max of a or b, comparing them by a[1] and b[1], and breaking ties to the left. Useful for implementing argmax operations:\n\njulia> a = [7.7, 3.3, 9.9, 3.3, 9.9]; x = Scalar(-Inf => 0);\n\njulia> @finch @loop i x[] <<maxby>>= a[i] => i;\n\njulia> x[]\n9.9 => 3\n\n\n\n\n\n","category":"function"},{"location":"algebra/#Properties","page":"Custom Functions","title":"Properties","text":"","category":"section"},{"location":"algebra/","page":"Custom Functions","title":"Custom Functions","text":"The full list of properties recognized by Finch is as follows (use these to declare the properties of your own functions):","category":"page"},{"location":"algebra/","page":"Custom Functions","title":"Custom Functions","text":"isassociative\niscommutative\nisdistributive\nisidempotent\nisidentity\nisannihilator\nisinverse\nisinvolution","category":"page"},{"location":"algebra/#Finch.isassociative","page":"Custom Functions","title":"Finch.isassociative","text":"isassociative(algebra, f)\n\nReturn true when f(a..., f(b...), c...) = f(a..., b..., c...) in algebra.\n\n\n\n\n\n","category":"function"},{"location":"algebra/#Finch.iscommutative","page":"Custom Functions","title":"Finch.iscommutative","text":"iscommutative(algebra, f)\n\nReturn true when for all permutations p, f(a...) = f(a[p]...) in algebra.\n\n\n\n\n\n","category":"function"},{"location":"algebra/#Finch.isdistributive","page":"Custom Functions","title":"Finch.isdistributive","text":"isidempotent(algebra, f)\n\nReturn true when f(a, b) = f(f(a, b), b) in algebra.\n\n\n\n\n\n","category":"function"},{"location":"algebra/#Finch.isidempotent","page":"Custom Functions","title":"Finch.isidempotent","text":"isidempotent(algebra, f)\n\nReturn true when f(a, b) = f(f(a, b), b) in algebra.\n\n\n\n\n\n","category":"function"},{"location":"algebra/#Finch.isidentity","page":"Custom Functions","title":"Finch.isidentity","text":"isidentity(algebra, f, x)\n\nReturn true when f(a..., x, b...) = f(a..., b...) in algebra.\n\n\n\n\n\n","category":"function"},{"location":"algebra/#Finch.isannihilator","page":"Custom Functions","title":"Finch.isannihilator","text":"isannihilator(algebra, f, x)\n\nReturn true when f(a..., x, b...) = x in algebra.\n\n\n\n\n\n","category":"function"},{"location":"algebra/#Finch.isinverse","page":"Custom Functions","title":"Finch.isinverse","text":"isinverse(algebra, f, g)\n\nReturn true when f(a, g(a)) is the identity under f in algebra.\n\n\n\n\n\n","category":"function"},{"location":"algebra/#Finch.isinvolution","page":"Custom Functions","title":"Finch.isinvolution","text":"isinvolution(algebra, f)\n\nReturn true when f(f(a)) = a in algebra.\n\n\n\n\n\n","category":"function"},{"location":"algebra/#Finch-Kernel-Caching","page":"Custom Functions","title":"Finch Kernel Caching","text":"","category":"section"},{"location":"algebra/","page":"Custom Functions","title":"Custom Functions","text":"Finch code is cached when you first run it. Thus, if you run a Finch function once, then make changes to the Finch compiler (like defining new properties), the cached code will be used and the changes will not be reflected.","category":"page"},{"location":"algebra/","page":"Custom Functions","title":"Custom Functions","text":"It's best to design your code so that modifications to the Finch compiler occur before any Finch functions are called. However, if you really need to modify a precompiled Finch kernel, you can call Finch.refresh() to invalidate the code cache.","category":"page"},{"location":"algebra/","page":"Custom Functions","title":"Custom Functions","text":"refresh","category":"page"},{"location":"algebra/#Finch.refresh","page":"Custom Functions","title":"Finch.refresh","text":"Finch.refresh()\n\nFinch caches the code for kernels as soon as they are run. If you modify the Finch compiler after running a kernel, you'll need to invalidate the Finch caches to reflect these changes by calling Finch.refresh(). This function should only be called at global scope, and never during precompilation.\n\n\n\n\n\n","category":"function"},{"location":"algebra/#(Advanced)-On-World-Age-and-Generated-Functions","page":"Custom Functions","title":"(Advanced) On World-Age and Generated Functions","text":"","category":"section"},{"location":"algebra/","page":"Custom Functions","title":"Custom Functions","text":"Julia uses a \"world age\" to describe the set of defined functions at a point in time. Generated functions run in the same world age in which they were defined, so they can't call functions defined after the generated function. This means that if Finch used normal generated functions, users can't define their own functions without first redefining all of Finch's generated functions.","category":"page"},{"location":"algebra/","page":"Custom Functions","title":"Custom Functions","text":"Finch uses special generators that run in the current world age, but do not update with subsequent compiler function invalidations. If two packages modify the behavior of Finch in different ways, and call those Finch functions during precompilation, the resulting behavior is undefined.","category":"page"},{"location":"algebra/","page":"Custom Functions","title":"Custom Functions","text":"There are several packages that take similar, but different, approaches to allow user participation in staged Julia programming (not to mention Base eval or @generated): StagedFunctions.jl, GeneralizedGenerated.jl, RuntimeGeneratedFunctions.jl, or Zygote.jl.","category":"page"},{"location":"algebra/","page":"Custom Functions","title":"Custom Functions","text":"Our approach is most similar to that of StagedFunctions.jl or Zygote.jl. We chose our approach to be the simple and flexible while keeping the kernel call overhead low.","category":"page"},{"location":"algebra/#(Advanced)-Separate-Algebras","page":"Custom Functions","title":"(Advanced) Separate Algebras","text":"","category":"section"},{"location":"algebra/","page":"Custom Functions","title":"Custom Functions","text":"If you want to define non-standard properties or custom rewrite rules for some functions in a separate context, you can represent these changes with your own algebra type.  We express this by subtyping AbstractAlgebra and defining properties as follows:","category":"page"},{"location":"algebra/","page":"Custom Functions","title":"Custom Functions","text":"struct MyAlgebra <: AbstractAlgebra end\n\nFinch.isassociative(::MyAlgebra, ::typeof(gcd)) = true\nFinch.iscommutative(::MyAlgebra, ::typeof(gcd)) = true\nFinch.isannihilator(::MyAlgebra, ::typeof(gcd), x) = x == 1","category":"page"},{"location":"algebra/","page":"Custom Functions","title":"Custom Functions","text":"We pass the algebra to Finch as an optional first argument:","category":"page"},{"location":"algebra/","page":"Custom Functions","title":"Custom Functions","text":"@finch MyAlgebra() (w .= 1; @loop i w[i] = gcd(u[i], v[i]))","category":"page"},{"location":"algebra/#Rewriting","page":"Custom Functions","title":"Rewriting","text":"","category":"section"},{"location":"algebra/","page":"Custom Functions","title":"Custom Functions","text":"Define custom rewrite rules by overloading the get_program_rules function on your algebra.  Unless you want to write the full rule set from scratch, be sure to append your new rules to the old rules, which can be obtained by calling get_program_rules with another algebra. Rules can be specified directly on Finch IR using RewriteTools.jl.","category":"page"},{"location":"algebra/","page":"Custom Functions","title":"Custom Functions","text":"base_rules\ngetrules","category":"page"},{"location":"fileio/","page":"Tensor File I/O","title":"Tensor File I/O","text":"CurrentModule = Finch","category":"page"},{"location":"fileio/#Finch-Tensor-File-Input/Output","page":"Tensor File I/O","title":"Finch Tensor File Input/Output","text":"","category":"section"},{"location":"fileio/","page":"Tensor File I/O","title":"Tensor File I/O","text":"Finch supports many input/output tensor file formats.","category":"page"},{"location":"fileio/#Finch-Format-(.fbr)","page":"Tensor File I/O","title":"Finch Format (.fbr)","text":"","category":"section"},{"location":"fileio/","page":"Tensor File I/O","title":"Tensor File I/O","text":"Finch's custom binary file format for fibers is best suited to users who plan to exclusively use Finch in Julia (perhaps across different platforms). This format straightforwardly maps the fields of Finch fiber formats to arrays in data containers (currently Finch only supports HDF5, but if you file an issue someone might add Numpy NPZ). Arrays are stored 1-indexed as they would be in memory.","category":"page"},{"location":"fileio/","page":"Tensor File I/O","title":"Tensor File I/O","text":"fbrwrite\nfbrread","category":"page"},{"location":"fileio/#Finch.fbrwrite","page":"Tensor File I/O","title":"Finch.fbrwrite","text":"fbrwrite(filename, tns)\n\nWrite the Finch fiber using Finch's custom binary HDF5 file format.\n\nHDF5 must be loaded for this function to be available\n\n\n\n\n\n","category":"function"},{"location":"fileio/#Finch.fbrread","page":"Tensor File I/O","title":"Finch.fbrread","text":"fbrread(filename)\n\nRead the Finch fiber using Finch's custom binary HDF5 file format.\n\nHDF5 must be loaded for this function to be available\n\n\n\n\n\n","category":"function"},{"location":"fileio/#Binsparse-Format-(.fbr)","page":"Tensor File I/O","title":"Binsparse Format (.fbr)","text":"","category":"section"},{"location":"fileio/","page":"Tensor File I/O","title":"Tensor File I/O","text":"Finch supports the most recent revision of the Binsparse binary sparse tensor format, as well as the proposed v2.0 tensor extension. This is a good option for those who want an efficient way to transfer sparse tensors between supporting libraries and languages. The Binsparse format represents the tensor format as a JSON string in the underlying data container (currently Finch only supports HDF5, but if you file an issue someone might add Numpy NPZ). Binsparse arrays are stored 0-indexed.","category":"page"},{"location":"fileio/","page":"Tensor File I/O","title":"Tensor File I/O","text":"bswrite\nbsread","category":"page"},{"location":"fileio/#Finch.bswrite","page":"Tensor File I/O","title":"Finch.bswrite","text":"bswrite(filename, tns)\n\nWrite the Finch fiber to a file using  Binsparse HDF5 file format.\n\nHDF5 must be loaded for this function to be available\n\nwarning: Warning\nThe Binsparse spec is under development. Additionally, this function may not be fully conformant. Please file bug reports if you see anything amiss.\n\n\n\n\n\n","category":"function"},{"location":"fileio/#Finch.bsread","page":"Tensor File I/O","title":"Finch.bsread","text":"bsread(filename)\n\nRead the Binsparse HDF5 file into a Finch tensor.\n\nHDF5 must be loaded for this function to be available\n\nwarning: Warning\nThe Binsparse spec is under development. Additionally, this function may not be fully conformant. Please file bug reports if you see anything amiss.\n\n\n\n\n\n","category":"function"},{"location":"fileio/#TensorMarket-(.mtx,-.ttx)","page":"Tensor File I/O","title":"TensorMarket (.mtx, .ttx)","text":"","category":"section"},{"location":"fileio/","page":"Tensor File I/O","title":"Tensor File I/O","text":"Finch supports the MatrixMarket and TensorMarket formats, which prioritize readability and archiveability, storing matrices and tensors in plaintext.","category":"page"},{"location":"fileio/","page":"Tensor File I/O","title":"Tensor File I/O","text":"fttwrite\nfttread","category":"page"},{"location":"fileio/#Finch.fttwrite","page":"Tensor File I/O","title":"Finch.fttwrite","text":"fttwrite(filename, tns)\n\nWrite a sparse Finch fiber to a TensorMarket file.\n\nTensorMarket must be loaded for this function to be available.\n\nSee also: ttwrite\n\n\n\n\n\n","category":"function"},{"location":"fileio/#Finch.fttread","page":"Tensor File I/O","title":"Finch.fttread","text":"fttread(filename, infoonly=false, retcoord=false)\n\nRead the TensorMarket file into a Finch fiber. The fiber will be dense or COO depending on the format of the file.\n\nTensorMarket must be loaded for this function to be available.\n\nSee also: ttread\n\n\n\n\n\n","category":"function"}]
}
